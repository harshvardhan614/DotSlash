<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>


        *{
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body{
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: #f5f5f5;
            height:7rem;
        }

        h1 {
            background-color: #3498db;
            padding: 20px ;
            text-align: center;
            color: white;
            font-size: 24px;
            width: 100%;

        }

        main {
            display: flex;
            justify-content: center;
            align-items: center;
            flex-wrap: wrap;
            margin: 20px;
            width: 100%;
            max-width: 1200px;
            height:100%;
        }

        #video-container {
        
            max-width: 500px;
            width:50%;
            margin:0px auto;
            overflow: hidden;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.2);
        }

        video {
            width: 100%;
            height: auto;
            display: block;
        }

        #robot-image {
            width: 200px;
            height: 200px;
            margin-top: 20px;
        }

        #chat-container {
            width: 50%;
            max-width: 500px;
            padding: 20px;
            background-color: #ffffff;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            margin: 20px auto 0;
            box-sizing: border-box;
        }

        .question {
            margin-bottom: 10px;
            font-weight: bold;
        }

        .answer {
            margin-bottom: 20px;
        }
        .btns{
            display:flex;
            align-items:center;
            justify-content:space-evenly;
        }

        .btns button{
            padding:10px 15px;
            margin:5px;
            background:blue;
            color:white;
            outline:none;
        }

        @media only screen and (max-width: 768px) {
            main {
                flex-direction: column;
                align-items: center;
            }

            #video-container, #chat-container {
                width: 100%;
                margin-bottom: 20px;
            }
        }
    </style>
</head>
<body>
    <h1>
        AI Interview Interface
    </h1>
    <main>
        <div id="video-container">
            <video id="video" playsinline autoplay muted></video>

            <div>
                <centre>
                    <br>
                    <p style="display:inline-block;">Candidate Confidence :- </p>
                    <b><span id="confidence-percent">0%</span></b>
            </centre>
            </div>
        </div>
        <!--div id="robot-image">
            <img src="robot-image.jpg" alt="Robot Image">
        </div-->
        <div id="chat-container">
            <div id="chat">
                <div id="question-display-box" class="question"></div>
                <!-- Additional questions and answers can be dynamically added here -->
            </div>
            <div class='btns'>
                <button id="next-question" onclick="next_question()" style="display: none;">Submit Question</button>
                <button id="interview-submit" style="display:none" onclick="submit_interview()">Final Submit</button>
                <button id="start-interview" onclick="start_interview()">Start Interview</button>
            </div>
        </div>
        
    </main>

    
    <script>
        var server_url = '';
        var ques_index = -1;
        var interview_data = [];
        var questions = [];

        

        var leftchannel = [];
        var rightchannel = [];
        var recorder = null;
        var recordingLength = 0;
        var volume = null;
        var mediaStream = null;
        var sampleRate = 44100;
        var context = null;
        var blob = null;
        var questions_num = 0;

        
        function start_recording(){
            leftchannel = [];
            rightchannel = [];
            recorder = null;
             recordingLength = 0;
             volume = null;
             mediaStream = null;
             sampleRate = 44100;
             context = null;
             blob = null;
            // Initialize recorder
            navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
            navigator.getUserMedia(
            {
                audio: true
            },
            function (e) {
                console.log("user consent");

                // creates the audio context
                window.AudioContext = window.AudioContext || window.webkitAudioContext;
                context = new AudioContext();

                // creates an audio node from the microphone incoming stream
                mediaStream = context.createMediaStreamSource(e);

                // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor
                // bufferSize: the onaudioprocess event is called when the buffer is full
                var bufferSize = 2048;
                var numberOfInputChannels = 2;
                var numberOfOutputChannels = 2;
                if (context.createScriptProcessor) {
                    recorder = context.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels);
                } else {
                    recorder = context.createJavaScriptNode(bufferSize, numberOfInputChannels, numberOfOutputChannels);
                }

                recorder.onaudioprocess = function (e) {
                    leftchannel.push(new Float32Array(e.inputBuffer.getChannelData(0)));
                    rightchannel.push(new Float32Array(e.inputBuffer.getChannelData(1)));
                    recordingLength += bufferSize;
                }

                // we connect the recorder
                mediaStream.connect(recorder);
                recorder.connect(context.destination);
            },
                        function (e) {
                            console.error(e);
                        });
                    }
        
                    

        function send_recording(qno){
            // stop recording
            recorder.disconnect(context.destination);
            mediaStream.disconnect(recorder);

            // we flat the left and right channels down
            // Float32Array[] => Float32Array
            var leftBuffer = flattenArray(leftchannel, recordingLength);
            var rightBuffer = flattenArray(rightchannel, recordingLength);
            // we interleave both channels together
            // [left[0],right[0],left[1],right[1],...]
            var interleaved = interleave(leftBuffer, rightBuffer);

            // we create our wav file
            var buffer = new ArrayBuffer(44 + interleaved.length * 2);
            var view = new DataView(buffer);

            // RIFF chunk descriptor
            writeUTFBytes(view, 0, 'RIFF');
            view.setUint32(4, 44 + interleaved.length * 2, true);
            writeUTFBytes(view, 8, 'WAVE');
            // FMT sub-chunk
            writeUTFBytes(view, 12, 'fmt ');
            view.setUint32(16, 16, true); // chunkSize
            view.setUint16(20, 1, true); // wFormatTag
            view.setUint16(22, 2, true); // wChannels: stereo (2 channels)
            view.setUint32(24, sampleRate, true); // dwSamplesPerSec
            view.setUint32(28, sampleRate * 4, true); // dwAvgBytesPerSec
            view.setUint16(32, 4, true); // wBlockAlign
            view.setUint16(34, 16, true); // wBitsPerSample
            // data sub-chunk
            writeUTFBytes(view, 36, 'data');
            view.setUint32(40, interleaved.length * 2, true);

            // write the PCM samples
            var index = 44;
            var volume = 1;
            for (var i = 0; i < interleaved.length; i++) {
                view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
                index += 2;
            }

            // our final blob
            blob = new Blob([view], { type: 'audio/wav' });
            
            send_audio_for_transcription(blob, qno);
    }
        
    function send_audio_for_transcription(blob, qno){
        const formData = new FormData();
        formData.append('audio', blob, 'recording.webm');
        formData.append('qno', qno);
        //formData.append('audio', audioBlob, 'recording.ogg');
       
        console.log(formData);
        fetch(server_url+'/transcribe', {
          method: 'POST',
          body: formData
        })
        .then(response => response.json())
        .then(data => {
          console.log('Audio uploaded successfully:', data);

          interview_data[parseInt(data['qno'])]['transcription'] = data['transcript'];
        })
        .catch(error => {
          console.error('Error uploading audio:', error);
        });
    }
        
        function flattenArray(channelBuffer, recordingLength) {
            var result = new Float32Array(recordingLength);
            var offset = 0;
            for (var i = 0; i < channelBuffer.length; i++) {
                var buffer = channelBuffer[i];
                result.set(buffer, offset);
                offset += buffer.length;
            }
            return result;
        }

        function interleave(leftChannel, rightChannel) {
            var length = leftChannel.length + rightChannel.length;
            var result = new Float32Array(length);

            var inputIndex = 0;

            for (var index = 0; index < length;) {
                result[index++] = leftChannel[inputIndex];
                result[index++] = rightChannel[inputIndex];
                inputIndex++;
            }
            return result;
        }

        function writeUTFBytes(view, offset, string) {
            for (var i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }


        // video starts from here
        const video = document.getElementById('video');
        const snapshotBtn = document.getElementById('snapshot-btn');

        // Get user media
        navigator.mediaDevices.getUserMedia({ video: true })
            .then((stream) => {
                video.srcObject = stream;
            })
            .catch((error) => {
                console.error('Error accessing webcam:', error);
            });

                
        function send_video_snap(){
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');
            context.drawImage(video, 0, 0, canvas.width, canvas.height);

            canvas.toBlob((blob) => {
                const formData = new FormData();
                formData.append('snapshot', blob, 'snapshot.png');

                // Send snapshot to backend using FormData
                fetch(server_url+'/snapshot', {
                    method: 'POST',
                    body: formData,
                })
                .then(response => response.json())
                .then(data => 
                {
                    console.log(data);
                    if(data){
                        if(data['confidence'] != null || data['confidence'] != undefined){
                            if(interview_data[ques_index]){
                                interview_data[ques_index]['video_confidence'].push(data.confidence);
                                document.querySelectorAll('#confidence-percent')[0].innerHTML = data.confidence+'%';
                            }
                            
                        }
                    }                    
                    
                }
                )
                .catch(error => console.error('Error sending snapshot:', error));
            }, 'image/png');
        }


        let video_interval;
        
        // main code

        // Function to terminate the interval after 15 seconds
        function stopVideoSnapshotsInterval() {
            clearInterval(video_interval);
        }
        
        function init_question(q_index){
            
            interview_data[q_index] = {
                "question" : questions[q_index]['question'],
                "video_confidence" : [],
                "transcription" : ""
            };
            

            // show the question using inner html
            document.querySelectorAll('#question-display-box')[0].innerHTML = questions[q_index]['question'];
        }

        function next_question(){
            if(ques_index < questions_num-1){
                // so that recording is not send for 0th ques
                if(ques_index != -1){
                    send_recording(ques_index);
                }
                start_recording();
                

                ques_index+=1;

                init_question(ques_index);
            }
            if(ques_index >= questions_num-1){
                //hide next button and show submit button
                document.querySelectorAll('#next-question')[0].style.display = 'none';
                document.querySelectorAll('#next-question')[0].disable = true;
                document.querySelectorAll('#interview-submit')[0].style.display = 'block';
            }

        }

        function start_interview(){
            
            // on click remove the top layer of start interview
            
            document.querySelectorAll('#next-question')[0].style.display = 'block';
            document.querySelectorAll('#start-interview')[0].style.display = 'none';
            // Set interval to call the function every 5 seconds
            let video_interval = setInterval(send_video_snap, 5000);
            
            next_question();
        }

        function select_topics_and_get_questions(){
            // pass topic in below function
            fetch_questions('DSA');
            
            ///  chnage screen to a page showing a start interview page

        }


        function fetch_questions(topic){
            var payload = {
                'topic':topic
            };

        fetch(server_url+'/api/get_questions', {
            method: 'POST', 
            headers: {
                'Content-Type': 'application/json', // Specify content type as JSON
            },
            body: JSON.stringify(payload)
            })
            .then(response => response.json())
            .then(data => {
                console.log(data);
                questions = data['questions'];
                questions_num = data['questions'].length;
            })
            .catch(error => {
                console.error('Error getting questions:', error);
            });

        }
    
        
        function submit_interview(){
            var payload = interview_data;

        fetch(server_url+'/api/submit_interview', {
            method: 'POST', 
            headers: {
                'Content-Type': 'application/json', // Specify content type as JSON
            },
            body: JSON.stringify(payload)
            })
            .then(response => response.json())
            .then(data => {
                console.log(data);
                questions = data['questions'];
                questions_num = data['questions'].length;
            })
            .catch(error => {
                console.error('Error getting questions:', error);
            });

        }
    
        
        var urlParams = new URLSearchParams(window.location.search);

        // Retrieve specific parameters
        var param1Value = urlParams.get('mainOption');

        //select_topics_and_get_questions();
        fetch_questions(param1Value);
    </script>
</body>
</html>