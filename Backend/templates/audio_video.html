<!DOCTYPE html>

<html>
<head>
    <meta charset="utf-8" />
    <title></title>
</head>
<body>
    <h1>Audio</h1>

    <button id="startRecordingButton">Start recording</button>
    <button id="stopRecordingButton">Stop recording</button>
    

    <div id="video-container">
        <video id="video" playsinline autoplay></video>
        <button id="snapshot-btn">Take Snapshot</button>
    </div>

    <script>
        var server_url = '';
        var ques_index = 0;
        var interview_data = [];
        var questions = [];

        var startRecordingButton = document.getElementById("startRecordingButton");
        var stopRecordingButton = document.getElementById("stopRecordingButton");
        

        var leftchannel = [];
        var rightchannel = [];
        var recorder = null;
        var recordingLength = 0;
        var volume = null;
        var mediaStream = null;
        var sampleRate = 44100;
        var context = null;
        var blob = null;

        startRecordingButton.addEventListener("click", function () {
            start_recording();
        });
        
        function start_recording(){
            
            // Initialize recorder
            navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;
            navigator.getUserMedia(
            {
                audio: true
            },
            function (e) {
                console.log("user consent");

                // creates the audio context
                window.AudioContext = window.AudioContext || window.webkitAudioContext;
                context = new AudioContext();

                // creates an audio node from the microphone incoming stream
                mediaStream = context.createMediaStreamSource(e);

                // https://developer.mozilla.org/en-US/docs/Web/API/AudioContext/createScriptProcessor
                // bufferSize: the onaudioprocess event is called when the buffer is full
                var bufferSize = 2048;
                var numberOfInputChannels = 2;
                var numberOfOutputChannels = 2;
                if (context.createScriptProcessor) {
                    recorder = context.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels);
                } else {
                    recorder = context.createJavaScriptNode(bufferSize, numberOfInputChannels, numberOfOutputChannels);
                }

                recorder.onaudioprocess = function (e) {
                    leftchannel.push(new Float32Array(e.inputBuffer.getChannelData(0)));
                    rightchannel.push(new Float32Array(e.inputBuffer.getChannelData(1)));
                    recordingLength += bufferSize;
                }

                // we connect the recorder
                mediaStream.connect(recorder);
                recorder.connect(context.destination);
            },
                        function (e) {
                            console.error(e);
                        });
                    }
        

        stopRecordingButton.addEventListener("click", function () {

            send_recording();
     
        });

        function send_recording(){
            // stop recording
            recorder.disconnect(context.destination);
            mediaStream.disconnect(recorder);

            // we flat the left and right channels down
            // Float32Array[] => Float32Array
            var leftBuffer = flattenArray(leftchannel, recordingLength);
            var rightBuffer = flattenArray(rightchannel, recordingLength);
            // we interleave both channels together
            // [left[0],right[0],left[1],right[1],...]
            var interleaved = interleave(leftBuffer, rightBuffer);

            // we create our wav file
            var buffer = new ArrayBuffer(44 + interleaved.length * 2);
            var view = new DataView(buffer);

            // RIFF chunk descriptor
            writeUTFBytes(view, 0, 'RIFF');
            view.setUint32(4, 44 + interleaved.length * 2, true);
            writeUTFBytes(view, 8, 'WAVE');
            // FMT sub-chunk
            writeUTFBytes(view, 12, 'fmt ');
            view.setUint32(16, 16, true); // chunkSize
            view.setUint16(20, 1, true); // wFormatTag
            view.setUint16(22, 2, true); // wChannels: stereo (2 channels)
            view.setUint32(24, sampleRate, true); // dwSamplesPerSec
            view.setUint32(28, sampleRate * 4, true); // dwAvgBytesPerSec
            view.setUint16(32, 4, true); // wBlockAlign
            view.setUint16(34, 16, true); // wBitsPerSample
            // data sub-chunk
            writeUTFBytes(view, 36, 'data');
            view.setUint32(40, interleaved.length * 2, true);

            // write the PCM samples
            var index = 44;
            var volume = 1;
            for (var i = 0; i < interleaved.length; i++) {
                view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
                index += 2;
            }

            // our final blob
            blob = new Blob([view], { type: 'audio/wav' });
            
            send_audio_for_transcription(blob);
    }
        
    function send_audio_for_transcription(blob){
        const formData = new FormData();
        formData.append('audio', blob, 'recording.webm');
        //formData.append('audio', audioBlob, 'recording.ogg');
       
        console.log(formData);
        fetch(server_url+'/transcribe', {
          method: 'POST',
          body: formData
        })
        .then(response => response.json())
        .then(data => {
          console.log('Audio uploaded successfully:', data);
          audioPlayer.src = data.url; // Assuming the server responds with the URL of the uploaded audio file
        })
        .catch(error => {
          console.error('Error uploading audio:', error);
        });
    }
        
        function flattenArray(channelBuffer, recordingLength) {
            var result = new Float32Array(recordingLength);
            var offset = 0;
            for (var i = 0; i < channelBuffer.length; i++) {
                var buffer = channelBuffer[i];
                result.set(buffer, offset);
                offset += buffer.length;
            }
            return result;
        }

        function interleave(leftChannel, rightChannel) {
            var length = leftChannel.length + rightChannel.length;
            var result = new Float32Array(length);

            var inputIndex = 0;

            for (var index = 0; index < length;) {
                result[index++] = leftChannel[inputIndex];
                result[index++] = rightChannel[inputIndex];
                inputIndex++;
            }
            return result;
        }

        function writeUTFBytes(view, offset, string) {
            for (var i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }


        // video starts from here
        const video = document.getElementById('video');
        const snapshotBtn = document.getElementById('snapshot-btn');

        // Get user media
        navigator.mediaDevices.getUserMedia({ video: true })
            .then((stream) => {
                video.srcObject = stream;
            })
            .catch((error) => {
                console.error('Error accessing webcam:', error);
            });

        // Capture snapshot on button click
        snapshotBtn.addEventListener('click', () => {
            send_video_snap();
        });
        
        function send_video_snap(){
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const context = canvas.getContext('2d');
            context.drawImage(video, 0, 0, canvas.width, canvas.height);

            canvas.toBlob((blob) => {
                const formData = new FormData();
                formData.append('snapshot', blob, 'snapshot.png');

                // Send snapshot to backend using FormData
                fetch(server_url+'/snapshot', {
                    method: 'POST',
                    body: formData,
                })
                .then(response => response.json())
                .then(data => 
                {
                    if(data){
                        if(data['confidence']){
                            if(interview_data[ques_index]){
                                interview_data[ques_index]['video_confidence'].push(data.confidence);
                            }
                            
                        }
                    }                    
                    
                }
                )
                .catch(error => console.error('Error sending snapshot:', error));
            }, 'image/png');
        }


        let video_interval;
        
        // main code

        // Function to terminate the interval after 15 seconds
        function stopVideoSnapshotsInterval() {
            clearInterval(video_interval);
        }
        
        function init_question(q_index){

            interview_data[q_index] = {
                "question" : questions[q_index]
                "video_confidence" : [],
                "transcription" : ""
            };
            

            // show the question using inner html
        }

        function next_question(){
            

            ques_index+=1;

            init_question(ques_index);
            

        }

        function start_interview(){
            
            // on click remove the top layer of start interview

            // Set interval to call the function every 5 seconds
            let video_interval = setInterval(send_video_snap, 5000);
            

        }

        function select_topics_and_get_questions(){
            // pass topic in below function
            fetch_questions('DSA');

            ///  chnage screen to a page showing a start interview page

        }


        function fetch_questions(topic){
            var payload = {
                'topic':topic
            };

        fetch(server_url+'/get_questions', {
            method: 'POST', 
            headers: {
                'Content-Type': 'application/json', // Specify content type as JSON
            },
            body: JSON.stringify(payload)
            })
            .then(response => response.json())
            .then(data => {
                console.log(data);
                questions = data;
            
            })
            .catch(error => {
                console.error('Error getting questions:', error);
            });

        }
    </script>
</body>
</html>